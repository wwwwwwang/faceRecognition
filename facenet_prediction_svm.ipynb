{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Users\\Madhouse\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import sys\n",
    "sys.path.append(r'D:\\Users\\Madhouse\\tensorflow\\yobiface\\src')\n",
    "import utils\n",
    "\n",
    "import os\n",
    "from os.path import join as pjoin\n",
    "import copy\n",
    "import shutil\n",
    "import pickle\n",
    "import time as t\n",
    " \n",
    "import cv2  \n",
    "import detect_face  \n",
    "import time \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_pics(path):\n",
    "    data = {}\n",
    "    pics_ctr = 0\n",
    "    files= os.listdir(path)\n",
    "    for file in files: #遍历文件夹 \n",
    "        if not os.path.isdir(file): #判断是否是文件夹，不是文件夹才打开\n",
    "        #print(file)\n",
    "            person_dir = pjoin(path, file)\n",
    "            if(file.find(\".jpg\") > 0):\n",
    "                guy=file.split(\"/\")[-1][:-4]\n",
    "                #print(\"guy[%d]=%s\"%(pics_ctr,guy))\n",
    "                curr_pics = [utils.preproc(cv2.imread(person_dir))]\n",
    "                data[guy] = curr_pics\n",
    "                pics_ctr += len(curr_pics)\n",
    "    return data, pics_ctr\n",
    "\n",
    "def load_emb(path):\n",
    "    pickle_file = open(path, 'rb')\n",
    "    my_dict = pickle.load(pickle_file)\n",
    "    # 一定要注意 要写关闭文件\n",
    "    pickle_file.close()\n",
    "    print(\"read dict from file is finished\")\n",
    "    return my_dict\n",
    "\n",
    "def getTime():\n",
    "    return t.strftime('%Y-%m-%d %H:%M:%S',t.localtime())\n",
    "\n",
    "def weigth_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def getBatch1(arr_x, arr_y, iter_cnt, batch_size=100):\n",
    "    #assert (Temperature >= 0),\"Colder than absolute zero!\"\n",
    "    assert(len(arr_x)==len(arr_y)),\"lens of arr_x and arr_y are not equal...\"\n",
    "    length=len(arr_x)\n",
    "    maxcnt=length//batch_size + 1\n",
    "    iter_cnt=iter_cnt%maxcnt\n",
    "    start=batch_size*(iter_cnt)\n",
    "    end=min(batch_size*(iter_cnt+1),length)\n",
    "    return arr_x[start:end],arr_y[start:end]\n",
    "\n",
    "def getBatch(data_set, iter_cnt, batch_size=100):\n",
    "    length=len(data_set)\n",
    "    maxcnt=length//batch_size + 1\n",
    "    iter_cnt=iter_cnt%maxcnt\n",
    "    start=batch_size*(iter_cnt)\n",
    "    end=min(batch_size*(iter_cnt+1),length)\n",
    "    return data_set[start:end][:,1:],data_set[start:end][:,0]\n",
    "\n",
    "def nextBatch(data_set, iter_cnt, batch_size=100):\n",
    "    length=len(data_set)\n",
    "    maxcnt=length//batch_size + 1\n",
    "    iter_cnt=iter_cnt%maxcnt\n",
    "    start=batch_size*(iter_cnt)\n",
    "    end=min(batch_size*(iter_cnt+1),length)\n",
    "    return data_set[start:end][:,1:],np.expand_dims(data_set[start:end][:,0], axis=1)\n",
    "\n",
    "def fill_feed_dictCNN(data_set, type, images_pl, labels_pl, keep_prob, iter_cnt, batch_size=100):\n",
    "    \"\"\"Fills the feed_dict for training the given step.\n",
    "    A feed_dict takes the form of:\n",
    "    feed_dict = {\n",
    "        <placeholder>: <tensor of values to be passed for placeholder>,\n",
    "        ....\n",
    "    }\n",
    "    Args:\n",
    "      data_set: The set of images and labels, from input_data.read_data_sets()\n",
    "      images_pl: The images placeholder, from placeholder_inputs().\n",
    "      labels_pl: The labels placeholder, from placeholder_inputs().\n",
    "    Returns:\n",
    "      feed_dict: The feed dictionary mapping from placeholders to values.\n",
    "    \"\"\"\n",
    "    # Create the feed_dict for the placeholders filled with the next\n",
    "    # `batch size ` examples.\n",
    "    #batch = data_set.next_batch(FLAGS.batch_size, FLAGS.fake_data)\n",
    "    x,y=getBatch(data_set, iter_cnt, batch_size)\n",
    "    kp = 0.5\n",
    "    if type.find(\"train\") == -1:\n",
    "        kp = 1.0 \n",
    "    feed_dict = {\n",
    "        images_pl: x,\n",
    "        labels_pl: y,\n",
    "      keep_prob: kp\n",
    "    }\n",
    "    return feed_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read dict from file is finished\n",
      "emb_arr length = 13268\n",
      "read dict from file is finished\n",
      "emb_map length = 5761\n",
      "(500, 512) (500, 1)\n"
     ]
    }
   ],
   "source": [
    "emb_arr = load_emb('emb_arr.pkl')\n",
    "print('emb_arr length = %d'%len(emb_arr))\n",
    "emb_map = load_emb('emb_map.pkl')\n",
    "print('emb_map length = %d'%len(emb_map))\n",
    "\n",
    "x,y=nextBatch(emb_arr, 0, 500)\n",
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating networks and loading parameters\n",
      "WARNING:tensorflow:From C:\\Users\\Madhouse\\detect_face.py:212: calling reduce_max (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From C:\\Users\\Madhouse\\detect_face.py:214: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "INFO:tensorflow:Restoring parameters from D:\\Users\\Madhouse\\tensorflow\\download\\20180402-114759\\model-20180402-114759.ckpt-275\n",
      "model restore finished.....\n"
     ]
    }
   ],
   "source": [
    "#face detection parameters  \n",
    "minsize = 20 # minimum size of face  \n",
    "threshold = [ 0.6, 0.7, 0.7 ]  # three steps's threshold  \n",
    "factor = 0.709 # scale factor \n",
    "print('Creating networks and loading parameters')  \n",
    "with tf.Graph().as_default():  \n",
    "    sess = tf.Session() \n",
    "    with sess.as_default():  \n",
    "        pnet, rnet, onet = detect_face.create_mtcnn(sess, './mtcnn_model/')\n",
    "        saver = tf.train.import_meta_graph(r'D:\\Users\\Madhouse\\tensorflow\\download\\20180402-114759\\model-20180402-114759.meta')\n",
    "        saver.restore(sess, r'D:\\Users\\Madhouse\\tensorflow\\download\\20180402-114759\\model-20180402-114759.ckpt-275')\n",
    "        images_placeholder = tf.get_default_graph().get_tensor_by_name(\"input:0\")\n",
    "        embeddings = tf.get_default_graph().get_tensor_by_name(\"embeddings:0\")\n",
    "        phase_train_placeholder = tf.get_default_graph().get_tensor_by_name(\"phase_train:0\")\n",
    "print(\"model restore finished.....\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_nbr=len(emb_map)\n",
    "x= tf.placeholder(\"float\", shape=[None, 512])\n",
    "y_ = tf.placeholder(\"float\", shape=[None, 1], name=\"y\")\n",
    "\n",
    "A = tf.Variable(tf.random_normal(shape=[512, 1]))\n",
    "b = tf.Variable(tf.random_normal(shape=[1, 1]))\n",
    "\n",
    "# 定义线性模型\n",
    "output = tf.subtract(tf.matmul(x, A), b)\n",
    "\n",
    "# Declare vector L2 'norm' function squared\n",
    "l2_norm = tf.reduce_sum(tf.square(A))\n",
    "\n",
    "# Loss = max(0, 1-pred*actual) + alpha * L2_norm(A)^2\n",
    "alpha = tf.constant([0.01])\n",
    "classification_term = tf.reduce_mean(tf.maximum(0., tf.subtract(1., tf.multiply(output, y_))))\n",
    "loss = tf.add(classification_term, tf.multiply(alpha, l2_norm))\n",
    "\n",
    "prediction=tf.sign(output)\n",
    "accuracy=tf.reduce_mean(tf.cast(tf.equal(prediction,y_),tf.float32))\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.01)\n",
    "train_op = optimizer.minimize(loss)\n",
    "\n",
    "se = tf.Session()\n",
    "se.run(tf.global_variables_initializer())\n",
    "with se.as_default():\n",
    "    batch_size=500\n",
    "    for i in range(10000):\n",
    "        #feed_dict=fill_feed_dictCNN(emb_arr, \"train\", x, y_, keep_prob, i, batch_size)\n",
    "        batch=nextBatch(emb_arr, i, batch_size)\n",
    "        tt = getTime()\n",
    "        if i%500 == 0:\n",
    "            train_accuracy = accuracy.eval(feed_dict={x:batch[0], y_:batch[1]})\n",
    "            print(\"[%s] step %d, training accuracy %g\"%(tt, i, train_accuracy))\n",
    "        train_op.run(feed_dict={x:batch[0], y_:batch[1]})\n",
    "        #train_op.run(feed_dict={x:batch[0], y_:batch[1], keep_prob: kp})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
