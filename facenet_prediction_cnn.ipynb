{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Users\\Madhouse\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import sys\n",
    "sys.path.append(r'D:\\Users\\Madhouse\\tensorflow\\yobiface\\src')\n",
    "import utils\n",
    "\n",
    "import os\n",
    "from os.path import join as pjoin\n",
    "import copy\n",
    "import shutil\n",
    "import pickle\n",
    "import time as t\n",
    " \n",
    "import cv2  \n",
    "import detect_face  \n",
    "import time \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_pics(path):\n",
    "    data = {}\n",
    "    pics_ctr = 0\n",
    "    files= os.listdir(path)\n",
    "    for file in files: #遍历文件夹 \n",
    "        if not os.path.isdir(file): #判断是否是文件夹，不是文件夹才打开\n",
    "        #print(file)\n",
    "            person_dir = pjoin(path, file)\n",
    "            if(file.find(\".jpg\") > 0):\n",
    "                guy=file.split(\"/\")[-1][:-4]\n",
    "                #print(\"guy[%d]=%s\"%(pics_ctr,guy))\n",
    "                curr_pics = [utils.preproc(cv2.imread(person_dir))]\n",
    "                data[guy] = curr_pics\n",
    "                pics_ctr += len(curr_pics)\n",
    "    return data, pics_ctr\n",
    "\n",
    "def load_emb(path):\n",
    "    pickle_file = open(path, 'rb')\n",
    "    my_dict = pickle.load(pickle_file)\n",
    "    # 一定要注意 要写关闭文件\n",
    "    pickle_file.close()\n",
    "    print(\"read dict from file is finished\")\n",
    "    return my_dict\n",
    "\n",
    "def getTime():\n",
    "    return t.strftime('%Y-%m-%d %H:%M:%S',t.localtime())\n",
    "\n",
    "def weigth_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], \n",
    "                         strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "def conv1d(x, W):\n",
    "    return tf.nn.conv1d(x, W, stride=1, padding='SAME')\n",
    "def max_pool_1d(x):\n",
    "    return tf.layers.max_pooling1d(x, pool_size=[2],strides=[2], padding='SAME')\n",
    "\n",
    "def normal_full_layer(input_layer,size):\n",
    "    input_size = int(input_layer.get_shape()[1])\n",
    "    W = weigth_variable([input_size, size])\n",
    "    b = bias_variable([size])\n",
    "    return tf.matmul(input_layer, W) +b\n",
    "\n",
    "def inferenceCNN(images, keep_prob, nbr_class):\n",
    "    W_conv1 = weigth_variable([5, 1, 32])\n",
    "    b_conv1 = bias_variable([32])\n",
    "        \n",
    "    x_image = tf.reshape(images, [-1, 512, 1])\n",
    "        \n",
    "    h_conv1 = tf.nn.relu(conv1d(x_image, W_conv1) + b_conv1)\n",
    "    h_pool1 = max_pool_1d(h_conv1)\n",
    "    \n",
    "    W_conv2 = weigth_variable([5, 32, 64])\n",
    "    b_conv2 = bias_variable([64])\n",
    "    \n",
    "    h_conv2 = tf.nn.relu(conv1d(h_pool1, W_conv2) + b_conv2)\n",
    "    h_pool2 = max_pool_1d(h_conv2)\n",
    "    \n",
    "    #W_fc1 = weigth_variable([64, 1024])\n",
    "    #b_fc1 = bias_variable([1024])\n",
    "    \n",
    "    #h_pool2_flat = tf.reshape(h_pool2, [-1, 64])\n",
    "    #h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "    #h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "    \n",
    "    #W_fc2 = weigth_variable([1024, nbr_class])\n",
    "    #b_fc2 = bias_variable([nbr_class])\n",
    "    #y_conv = tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)\n",
    "    \n",
    "    flat = tf.reshape(h_pool2,[-1,h_pool2.get_shape()[1]*h_pool2.get_shape()[2]])\n",
    "\n",
    "    fully_conected = tf.nn.relu(normal_full_layer(flat,1024))\n",
    "    \n",
    "    second_hidden_layer = tf.nn.relu(normal_full_layer(fully_conected,512))\n",
    "\n",
    "    full_one_dropout = tf.nn.dropout(second_hidden_layer,keep_prob=keep_prob)\n",
    "\n",
    "    y_pred = normal_full_layer(full_one_dropout,nbr_class)\n",
    "    pred_softmax = tf.nn.softmax(y_pred)\n",
    "\n",
    "    return pred_softmax\n",
    "\n",
    "def loss(logits, labels):\n",
    "    \"\"\"Calculates the loss from the logits and the labels.\n",
    "\n",
    "    Args:\n",
    "      logits: Logits tensor, float - [batch_size, NUM_CLASSES].\n",
    "      labels: Labels tensor, int32 - [batch_size].\n",
    "\n",
    "    Returns:\n",
    "      loss: Loss tensor of type float.\n",
    "    \"\"\"\n",
    "    labels = tf.to_int64(labels)\n",
    "    cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "        logits=logits, labels=labels, name='xentropy')\n",
    "    # softmax_cross_entropy_with_logits\n",
    "    lo = tf.reduce_mean(cross_entropy, name='xentropy_mean')\n",
    "    return lo\n",
    "\n",
    "def getBatch1(arr_x, arr_y, iter_cnt, batch_size=100):\n",
    "    #assert (Temperature >= 0),\"Colder than absolute zero!\"\n",
    "    assert(len(arr_x)==len(arr_y)),\"lens of arr_x and arr_y are not equal...\"\n",
    "    length=len(arr_x)\n",
    "    maxcnt=length//batch_size + 1\n",
    "    iter_cnt=iter_cnt%maxcnt\n",
    "    start=batch_size*(iter_cnt)\n",
    "    end=min(batch_size*(iter_cnt+1),length)\n",
    "    return arr_x[start:end],arr_y[start:end]\n",
    "\n",
    "def getBatch(data_set, iter_cnt, batch_size=100):\n",
    "    length=len(data_set)\n",
    "    maxcnt=length//batch_size + 1\n",
    "    iter_cnt=iter_cnt%maxcnt\n",
    "    start=batch_size*(iter_cnt)\n",
    "    end=min(batch_size*(iter_cnt+1),length)\n",
    "    return data_set[start:end][:,1:],data_set[start:end][:,0]\n",
    "\n",
    "def fill_feed_dictCNN(data_set, type, images_pl, labels_pl, keep_prob, iter_cnt, batch_size=100):\n",
    "    \"\"\"Fills the feed_dict for training the given step.\n",
    "    A feed_dict takes the form of:\n",
    "    feed_dict = {\n",
    "        <placeholder>: <tensor of values to be passed for placeholder>,\n",
    "        ....\n",
    "    }\n",
    "    Args:\n",
    "      data_set: The set of images and labels, from input_data.read_data_sets()\n",
    "      images_pl: The images placeholder, from placeholder_inputs().\n",
    "      labels_pl: The labels placeholder, from placeholder_inputs().\n",
    "    Returns:\n",
    "      feed_dict: The feed dictionary mapping from placeholders to values.\n",
    "    \"\"\"\n",
    "    # Create the feed_dict for the placeholders filled with the next\n",
    "    # `batch size ` examples.\n",
    "    #batch = data_set.next_batch(FLAGS.batch_size, FLAGS.fake_data)\n",
    "    x,y=getBatch(data_set, iter_cnt, batch_size)\n",
    "    kp = 0.5\n",
    "    if type.find(\"train\") == -1:\n",
    "        kp = 1.0 \n",
    "    feed_dict = {\n",
    "        images_pl: x,\n",
    "        labels_pl: y,\n",
    "      keep_prob: kp\n",
    "    }\n",
    "    return feed_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read dict from file is finished\n",
      "emb_arr length = 13268\n",
      "read dict from file is finished\n",
      "emb_map length = 5761\n",
      "(500, 512) (500,)\n"
     ]
    }
   ],
   "source": [
    "emb_arr = load_emb('emb_arr.pkl')\n",
    "print('emb_arr length = %d'%len(emb_arr))\n",
    "emb_map = load_emb('emb_map.pkl')\n",
    "print('emb_map length = %d'%len(emb_map))\n",
    "\n",
    "x,y=getBatch(emb_arr, 0, 500)\n",
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating networks and loading parameters\n",
      "WARNING:tensorflow:From C:\\Users\\Madhouse\\detect_face.py:212: calling reduce_max (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From C:\\Users\\Madhouse\\detect_face.py:214: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "INFO:tensorflow:Restoring parameters from D:\\Users\\Madhouse\\tensorflow\\download\\20180402-114759\\model-20180402-114759.ckpt-275\n",
      "model restore finished.....\n"
     ]
    }
   ],
   "source": [
    "#face detection parameters  \n",
    "minsize = 20 # minimum size of face  \n",
    "threshold = [ 0.6, 0.7, 0.7 ]  # three steps's threshold  \n",
    "factor = 0.709 # scale factor \n",
    "print('Creating networks and loading parameters')  \n",
    "with tf.Graph().as_default():  \n",
    "    sess = tf.Session() \n",
    "    with sess.as_default():  \n",
    "        pnet, rnet, onet = detect_face.create_mtcnn(sess, './mtcnn_model/')\n",
    "        saver = tf.train.import_meta_graph(r'D:\\Users\\Madhouse\\tensorflow\\download\\20180402-114759\\model-20180402-114759.meta')\n",
    "        saver.restore(sess, r'D:\\Users\\Madhouse\\tensorflow\\download\\20180402-114759\\model-20180402-114759.ckpt-275')\n",
    "        images_placeholder = tf.get_default_graph().get_tensor_by_name(\"input:0\")\n",
    "        embeddings = tf.get_default_graph().get_tensor_by_name(\"embeddings:0\")\n",
    "        phase_train_placeholder = tf.get_default_graph().get_tensor_by_name(\"phase_train:0\")\n",
    "print(\"model restore finished.....\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 5761)\n",
      "[2018-06-27 09:33:24] step 0, training accuracy 1%\n",
      "[2018-06-27 09:36:41] step 200, training accuracy 0%\n",
      "[2018-06-27 09:39:55] step 400, training accuracy 0%\n",
      "[2018-06-27 09:43:06] step 600, training accuracy 0%\n",
      "[2018-06-27 09:46:21] step 800, training accuracy 0%\n",
      "[2018-06-27 09:49:35] step 1000, training accuracy 0%\n",
      "[2018-06-27 09:52:50] step 1200, training accuracy 0%\n",
      "[2018-06-27 09:56:32] step 1400, training accuracy 0%\n",
      "[2018-06-27 10:00:12] step 1600, training accuracy 0%\n",
      "[2018-06-27 10:03:28] step 1800, training accuracy 0%\n",
      "[2018-06-27 10:06:52] step 2000, training accuracy 0%\n",
      "[2018-06-27 10:10:18] step 2200, training accuracy 0%\n",
      "[2018-06-27 10:13:38] step 2400, training accuracy 0%\n",
      "[2018-06-27 10:17:02] step 2600, training accuracy 0%\n",
      "[2018-06-27 10:20:24] step 2800, training accuracy 0%\n",
      "[2018-06-27 10:23:53] step 3000, training accuracy 0%\n",
      "[2018-06-27 10:27:30] step 3200, training accuracy 1%\n",
      "[2018-06-27 10:31:04] step 3400, training accuracy 0%\n",
      "[2018-06-27 10:34:33] step 3600, training accuracy 0%\n",
      "[2018-06-27 10:38:01] step 3800, training accuracy 1%\n",
      "[2018-06-27 10:41:27] step 4000, training accuracy 0%\n",
      "[2018-06-27 10:44:54] step 4200, training accuracy 0%\n",
      "[2018-06-27 10:48:17] step 4400, training accuracy 0%\n",
      "[2018-06-27 10:51:47] step 4600, training accuracy 1%\n",
      "[2018-06-27 10:55:17] step 4800, training accuracy 0%\n",
      "[2018-06-27 10:58:41] step 5000, training accuracy 0%\n",
      "[2018-06-27 11:01:59] step 5200, training accuracy 0%\n",
      "[2018-06-27 11:05:07] step 5400, training accuracy 1%\n",
      "[2018-06-27 11:08:14] step 5600, training accuracy 0%\n",
      "[2018-06-27 11:11:21] step 5800, training accuracy 0%\n",
      "[2018-06-27 11:14:29] step 6000, training accuracy 0%\n",
      "[2018-06-27 11:17:36] step 6200, training accuracy 0%\n",
      "[2018-06-27 11:20:58] step 6400, training accuracy 1%\n",
      "[2018-06-27 11:24:22] step 6600, training accuracy 0%\n",
      "[2018-06-27 11:27:51] step 6800, training accuracy 0%\n",
      "[2018-06-27 11:31:16] step 7000, training accuracy 0%\n",
      "[2018-06-27 11:34:42] step 7200, training accuracy 0%\n",
      "[2018-06-27 11:38:03] step 7400, training accuracy 0%\n",
      "[2018-06-27 11:41:27] step 7600, training accuracy 1%\n",
      "[2018-06-27 11:44:47] step 7800, training accuracy 0%\n",
      "[2018-06-27 11:48:13] step 8000, training accuracy 0%\n",
      "[2018-06-27 11:51:30] step 8200, training accuracy 0%\n",
      "[2018-06-27 11:54:57] step 8400, training accuracy 0%\n",
      "[2018-06-27 11:58:24] step 8600, training accuracy 0%\n",
      "[2018-06-27 12:01:41] step 8800, training accuracy 0%\n",
      "[2018-06-27 12:04:48] step 9000, training accuracy 0%\n",
      "[2018-06-27 12:07:53] step 9200, training accuracy 0%\n",
      "[2018-06-27 12:10:58] step 9400, training accuracy 0%\n",
      "[2018-06-27 12:14:04] step 9600, training accuracy 0%\n",
      "[2018-06-27 12:17:09] step 9800, training accuracy 0%\n",
      "[2018-06-27 12:20:14] step 10000, training accuracy 0%\n",
      "[2018-06-27 12:23:19] step 10200, training accuracy 0%\n",
      "[2018-06-27 12:26:24] step 10400, training accuracy 0%\n",
      "[2018-06-27 12:29:29] step 10600, training accuracy 0%\n",
      "[2018-06-27 12:32:34] step 10800, training accuracy 0%\n",
      "[2018-06-27 12:35:41] step 11000, training accuracy 0%\n",
      "[2018-06-27 12:38:57] step 11200, training accuracy 0%\n",
      "[2018-06-27 12:42:11] step 11400, training accuracy 1%\n",
      "[2018-06-27 12:45:32] step 11600, training accuracy 0%\n",
      "[2018-06-27 12:48:52] step 11800, training accuracy 0%\n",
      "[2018-06-27 12:52:18] step 12000, training accuracy 0%\n",
      "[2018-06-27 12:55:45] step 12200, training accuracy 0%\n",
      "[2018-06-27 12:59:11] step 12400, training accuracy 0%\n",
      "[2018-06-27 13:02:30] step 12600, training accuracy 0%\n",
      "[2018-06-27 13:05:57] step 12800, training accuracy 0%\n",
      "[2018-06-27 13:09:23] step 13000, training accuracy 0%\n",
      "[2018-06-27 13:12:37] step 13200, training accuracy 0%\n",
      "[2018-06-27 13:15:41] step 13400, training accuracy 0%\n",
      "[2018-06-27 13:18:47] step 13600, training accuracy 0%\n",
      "[2018-06-27 13:21:52] step 13800, training accuracy 0%\n",
      "[2018-06-27 13:24:57] step 14000, training accuracy 0%\n",
      "[2018-06-27 13:28:03] step 14200, training accuracy 0%\n",
      "[2018-06-27 13:31:07] step 14400, training accuracy 0%\n",
      "[2018-06-27 13:34:13] step 14600, training accuracy 0%\n",
      "[2018-06-27 13:37:18] step 14800, training accuracy 0%\n",
      "[2018-06-27 13:40:24] step 15000, training accuracy 0%\n",
      "[2018-06-27 13:43:31] step 15200, training accuracy 0%\n",
      "[2018-06-27 13:46:36] step 15400, training accuracy 0%\n",
      "[2018-06-27 13:49:41] step 15600, training accuracy 0%\n",
      "[2018-06-27 13:52:46] step 15800, training accuracy 0%\n",
      "[2018-06-27 13:55:52] step 16000, training accuracy 0%\n",
      "[2018-06-27 13:59:07] step 16200, training accuracy 1%\n",
      "[2018-06-27 14:02:26] step 16400, training accuracy 0%\n",
      "[2018-06-27 14:06:04] step 16600, training accuracy 0%\n",
      "[2018-06-27 14:09:27] step 16800, training accuracy 0%\n",
      "[2018-06-27 14:12:49] step 17000, training accuracy 0%\n",
      "[2018-06-27 14:16:10] step 17200, training accuracy 0%\n",
      "[2018-06-27 14:20:15] step 17400, training accuracy 0%\n",
      "[2018-06-27 14:23:58] step 17600, training accuracy 0%\n",
      "[2018-06-27 14:27:03] step 17800, training accuracy 0%\n",
      "[2018-06-27 14:30:08] step 18000, training accuracy 0%\n",
      "[2018-06-27 14:33:14] step 18200, training accuracy 0%\n",
      "[2018-06-27 14:36:41] step 18400, training accuracy 0%\n",
      "[2018-06-27 14:40:29] step 18600, training accuracy 0%\n",
      "[2018-06-27 14:44:26] step 18800, training accuracy 0%\n",
      "[2018-06-27 14:47:58] step 19000, training accuracy 1%\n",
      "[2018-06-27 14:51:09] step 19200, training accuracy 0%\n",
      "[2018-06-27 14:54:37] step 19400, training accuracy 0%\n",
      "[2018-06-27 14:58:05] step 19600, training accuracy 0%\n",
      "[2018-06-27 15:01:27] step 19800, training accuracy 0%\n",
      "[2018-06-27 15:04:41] step 20000, training accuracy 0%\n",
      "[2018-06-27 15:08:00] step 20200, training accuracy 0%\n",
      "[2018-06-27 15:11:12] step 20400, training accuracy 0%\n",
      "[2018-06-27 15:14:28] step 20600, training accuracy 1%\n",
      "[2018-06-27 15:17:46] step 20800, training accuracy 1%\n",
      "[2018-06-27 15:21:07] step 21000, training accuracy 0%\n",
      "[2018-06-27 15:24:29] step 21200, training accuracy 0%\n",
      "[2018-06-27 15:27:59] step 21400, training accuracy 0%\n",
      "[2018-06-27 15:31:48] step 21600, training accuracy 0%\n",
      "[2018-06-27 15:35:41] step 21800, training accuracy 0%\n",
      "[2018-06-27 15:39:19] step 22000, training accuracy 0%\n",
      "[2018-06-27 15:42:52] step 22200, training accuracy 0%\n",
      "[2018-06-27 15:46:36] step 22400, training accuracy 0%\n",
      "[2018-06-27 15:50:46] step 22600, training accuracy 0%\n",
      "[2018-06-27 15:55:10] step 22800, training accuracy 0%\n",
      "[2018-06-27 15:59:43] step 23000, training accuracy 0%\n",
      "[2018-06-27 16:03:17] step 23200, training accuracy 0%\n",
      "[2018-06-27 16:06:55] step 23400, training accuracy 0%\n",
      "[2018-06-27 16:10:39] step 23600, training accuracy 0%\n",
      "[2018-06-27 16:14:21] step 23800, training accuracy 0%\n",
      "[2018-06-27 16:17:45] step 24000, training accuracy 0%\n",
      "[2018-06-27 16:21:15] step 24200, training accuracy 0%\n",
      "[2018-06-27 16:24:49] step 24400, training accuracy 1%\n",
      "[2018-06-27 16:28:20] step 24600, training accuracy 0%\n",
      "[2018-06-27 16:31:47] step 24800, training accuracy 0%\n",
      "[2018-06-27 16:35:10] step 25000, training accuracy 0%\n",
      "[2018-06-27 16:38:37] step 25200, training accuracy 0%\n",
      "[2018-06-27 16:42:05] step 25400, training accuracy 0%\n",
      "[2018-06-27 16:45:31] step 25600, training accuracy 0%\n",
      "[2018-06-27 16:49:06] step 25800, training accuracy 0%\n",
      "[2018-06-27 16:52:42] step 26000, training accuracy 0%\n",
      "[2018-06-27 16:56:27] step 26200, training accuracy 1%\n",
      "[2018-06-27 17:00:17] step 26400, training accuracy 0%\n",
      "[2018-06-27 17:03:59] step 26600, training accuracy 0%\n",
      "[2018-06-27 17:07:36] step 26800, training accuracy 0%\n",
      "[2018-06-27 17:11:18] step 27000, training accuracy 1%\n",
      "[2018-06-27 17:15:00] step 27200, training accuracy 0%\n",
      "[2018-06-27 17:18:35] step 27400, training accuracy 0%\n",
      "[2018-06-27 17:22:18] step 27600, training accuracy 0%\n",
      "[2018-06-27 17:25:58] step 27800, training accuracy 0%\n",
      "[2018-06-27 17:29:43] step 28000, training accuracy 0%\n",
      "[2018-06-27 17:34:03] step 28200, training accuracy 0%\n",
      "[2018-06-27 17:38:12] step 28400, training accuracy 1%\n",
      "[2018-06-27 17:41:54] step 28600, training accuracy 0%\n",
      "[2018-06-27 17:45:21] step 28800, training accuracy 0%\n",
      "[2018-06-27 17:48:54] step 29000, training accuracy 1%\n",
      "[2018-06-27 17:52:19] step 29200, training accuracy 0%\n"
     ]
    }
   ],
   "source": [
    "class_nbr=len(emb_map)\n",
    "x= tf.placeholder(\"float\", shape=[None, 512])\n",
    "#y_ = tf.placeholder(tf.int32, shape=[None], name=\"y\")\n",
    "y_ = tf.placeholder(\"float\", shape=[None], name=\"y\")\n",
    "#y = tf.placeholder(tf.int32, shape=[None], name=\"y\")\n",
    "keep_prob = tf.placeholder(\"float\")\n",
    "\n",
    "logits=inferenceCNN(x, keep_prob, class_nbr)\n",
    "print(logits.shape)\n",
    "lo = loss(logits, y_)\n",
    "optimizer = tf.train.GradientDescentOptimizer(1e-4)\n",
    "train_op = optimizer.minimize(lo)\n",
    "#labels = tf.to_int64(labels)\n",
    "cp = tf.nn.in_top_k(logits, tf.to_int32(y_), 1)\n",
    "correct=tf.reduce_sum(tf.cast(cp, tf.int32))\n",
    "\n",
    "se = tf.Session()\n",
    "se.run(tf.global_variables_initializer())\n",
    "with se.as_default():\n",
    "    for i in range(50000):\n",
    "        batch_size=500\n",
    "        feed_dict=fill_feed_dictCNN(emb_arr, \"train\", x, y_, keep_prob, i, batch_size)\n",
    "        #batch=getBatch(emb_arr, i, batch_size)\n",
    "        kp = 0.5\n",
    "        tt = getTime()\n",
    "        if i%200 == 0:\n",
    "            train_accuracy = correct.eval(feed_dict=feed_dict)\n",
    "            print(\"[%s] step %d, training accuracy %g\"%(tt, i, train_accuracy))\n",
    "        train_op.run(feed_dict=feed_dict)\n",
    "        #train_op.run(feed_dict={x:batch[0], y_:batch[1], keep_prob: kp})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
